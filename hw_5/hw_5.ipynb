{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Homework 5"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Q1\n",
    "1. Compute the gradient $\\nabla f(x)$ and Hessian $\\nabla^{2} f(x)$ of the Rosenbrock\n",
    "function\n",
    "\n",
    "\\begin{aligned}\n",
    "f\\left(x_{1}, x_{2}\\right)=100\\left(x_{2}-x_{1}^{2}\\right)^{2}+\\left(1-x_{1}\\right)^{2}\n",
    "\\end{aligned}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Q1 Solution\n",
    "\n",
    "The gradient has the following form:\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla f=\\left[\\begin{array}{c}\n",
    "\\frac{\\partial f}{\\partial x_{1}} \\\\\n",
    "\\frac{\\partial f}{\\partial x_{2}}\n",
    "\\end{array}\\right]\n",
    "\\end{equation}\n",
    "\n",
    "Let's calculate the derivative with respect to $x_1$ first:\n",
    "\n",
    "\\begin{aligned}\n",
    "&\\frac{\\partial f}{\\partial x_{1}}=200\\left(x_{2}-x_{1}^{2}\\right)\\left(-2 x_{1}\\right)-2\\left(1-x_{1}\\right) \\\\\n",
    "&\\frac{\\partial f}{\\partial x_{1}}=-2\\left[\\left(200 x_{2}-200 x_{1}^{2}\\right)\\left(x_{1}\\right)+1-x_{1}\\right] \\\\\n",
    "&\\frac{\\partial f}{\\partial x_{1}}=-2\\left(200 x_{1} x_{2}-200 x_{1}^{3}+1-x_{1}\\right) \\\\\n",
    "&\\frac{\\partial f}{\\partial x_{1}}=2\\left(200 x_{1}^{3}-200 x_{1} x_{2}+x_{1}-1\\right)\n",
    "\\end{aligned}\n",
    "\n",
    "Then, we calculate the derivative with respect to $x_2$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial f}{\\partial x_{2}}=200\\left(x_{2}-x_{1}^{2}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "Thus, the gradient $\\nabla f(x)$ is:\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla f=\\left[\\begin{array}{c}\n",
    "2\\left(200 x_{1}^{3}-200 x_1 x_2+x_{1}-1\\right) \\\\\n",
    "200\\left(x_2-x_{1} 2\\right)\n",
    "\\end{array}\\right]\n",
    "\\end{equation}\n",
    "\n",
    "We will use the result above to derive the Hessian matrix which has the following form:\n",
    "\n",
    "\\begin{equation}\n",
    "\\textbf H f=\\left[\\begin{array}{ll}\n",
    "\\frac{\\partial^{2} f}{\\partial x_{1}^{2}} & \\frac{\\partial^{2} f}{\\partial x_{1} \\partial x_{2}} \\\\\n",
    "\\frac{\\partial^{2} f}{\\partial x_2 \\partial x_{1}} & \\frac{\\partial^{2} f}{\\partial x_{2}^{2}}\n",
    "\\end{array}\\right]\n",
    "\\end{equation}\n",
    "\n",
    "Using the previous results we have:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "&\\frac{\\partial^{2} f}{\\partial x_{1}^{2}}=1200 x_{1}^{2}-400 x_{2}+2 \\\\\n",
    "&\\frac{\\partial^{2} f}{\\partial x_{2}^{2}}=200 \\\\\n",
    "&\\frac{\\partial^{2} f}{\\partial x_{1} \\partial x_{2}}=-400 x_{1} \\\\\n",
    "&\\frac{\\partial^{2} f}{\\partial x_{2} \\partial x_{1}}=-400 x_{1}\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "And thus the Hessian matrix is:\n",
    "\n",
    "\\begin{equation}\n",
    "\\textbf H f=\\left[\\begin{array}{ll}\n",
    "1200x_1^2-400x_2 +2 & -400 x_1 \\\\\n",
    "-400 x_1 & 200\n",
    "\\end{array}\\right]\n",
    "\\end{equation}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Q2\n",
    "Implement the Newton’s Method with line search given in Algorithm 1. Use the Newton’s\n",
    "method to minimize the Rosenbrock function in Problem 1. Set the initial stepsize\n",
    "$\\bar{\\alpha}=1$ Select your own choice of $\\rho \\in(0,1), c \\in(0,1)$. First run the\n",
    "algorithm from the initial point $x^{0}=(1.2,1.2)^{\\top}$, and then try the more\n",
    "difficult starting point $x^{0}=(-1.2,1)^{\\top}$. For each starting point, print out\n",
    "the step length $\\alpha^{k}$ used by the algorithm as well as the point $x^{k}$ for\n",
    "every step $k$. You should observe that Newton's Method converges very fast.\n",
    "\n",
    "![Algorithm 1](algo_1.jpg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_0 = np.array([1.2, 1.2])\n",
    "alpha = 1\n",
    "rho = 0\n",
    "c = 0\n",
    "\n",
    "k = 0\n",
    "eps = 10 ** -4\n",
    "\n",
    "def f(x):\n",
    "    return 100 * (x[1] - x[0] ** 2) ** 2 + (1 - x[0]) ** 2\n",
    "\n",
    "def df(x):\n",
    "    nabla = np.zeros(2)\n",
    "    nabla[0] = 2 * (200 * x[0] ** 3 - 200 * x[0] * x[1] + x[0] - 1)\n",
    "    nabla[1] = 200 * (x[1] - x[0] ** 2)\n",
    "\n",
    "    return nabla\n",
    "\n",
    "def d2f(x):\n",
    "    hess = np.zeros((2, 2))\n",
    "    hess[0, 0] = 1200 * x[0] ** 2 - 400 * x[1] + 2\n",
    "    hess[1, 1] = 200\n",
    "    hess[0, 1] = hess[1, 0] = -400 * x[0]\n",
    "\n",
    "    return hess\n",
    "\n",
    "d_0 = - np.linalg.inv(d2f(x_0)) @ df(x_0)\n",
    "x = x_0\n",
    "\n",
    "while np.linalg.norm(df(x)) > eps:\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}